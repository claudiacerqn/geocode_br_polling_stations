---
title: Geocoding Brazilian Polling Stations with Administrative Data Sets
subtitle: 
author:
  name: F. Daniel Hidalgo
  affiliation: MIT
date: "`r format(Sys.time(), '%d %B %Y')`" ## Or "Lecture no."
output: 
  html_document:
    theme: flatly
    highlight: haddock
    # code_folding: show
    toc: yes
    toc_depth: 4
    toc_float: yes
    keep_md: false
    keep_tex: false ## Change to true if want keep intermediate .tex file
    css: preamble.css ## For multi-col environments
  pdf_document:
    latex_engine: xelatex
    toc: true
    dev: cairo_pdf
    # fig_width: 7 ## Optional: Set default PDF figure width
    # fig_height: 6 ## Optional: Set default PDF figure height
    includes:
      in_header: preamble.tex ## For multi-col environments
    pandoc_args:
        --template=mytemplate.tex ## For affiliation field. See: https://bit.ly/2T191uZ   
always_allow_html: true
urlcolor: blue
mainfont: cochineal
sansfont: Fira Sans
monofont: Fira Code ## Although, see: https://tex.stackexchange.com/q/294362
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = FALSE, dpi=300)
library(tidyverse)
library(drake)
library(gt)
library(sf)
```

This document outlines an approach to geocoding Brazilian polling station that heavily relies on administrative datasets.
In addition to detaling our approach, we also provide some evidence on the error of our method and how it compares to the [Google Maps Geocoding API](https://developers.google.com/maps/documentation/geocoding/overview).

Our general approach is to generate a series of candidate coordinates from a variety of administrative datasets.
We use a machine learning model trained on a subset of the data with coordinates provided by Supreme Electoral Tribunal (*TSE*) to choose among the candidate coordinates.
Inputs to this model are mostly measures of the quality of string matches between the polling station address and administrative data sources, as well as other characteristics of the address and municipality of the polling station.
For each polling station, we select the coordinates with the predicted smallest error among the possible coordinates.

## Data Sources

To geocode the polling stations, we leverage three main data sources:

-   *Cadastro Nacional de Endereços para Fins Estatísticos* (CNEFE) from the 2010 Census.
-   *Cadastro Nacional de Endereços para Fins Estatísticos* from the 2017 Agricultural Census.
-   *Catálogo de Escolas* from INEP.

The CNEFE datasets are national databases of addresses prepared by IBGE for the census and include detailed data on streets and addresses.
The 2010 version includes private addresses, as well as listings of government buildings (such as schools) and the names of local establishments (such as the names of schools or businesses).
The 2017[^1] version only includes agricultural properties.
Addresses in *rural* census tracts (*setores censitários*) in the 2010 CNEFE have longitude and latitude, while all agricultural properties in the 2017 CNEFE are geocoded.

[^1]: Details on the 2017 CNEFE can be found at this [link](https://biblioteca.ibge.gov.br/visualizacao/livros/liv101638_notas_tecnicas.pdf)

The 2010 Census data did not include coordinates for addresses in urban census tracts.
To partially overcome this issue, we compute the centroid of the census tract and assign this coordinate to each property in the urban census tract.
Because urban census tracts tend to be compact, tract centroid should still be fairly close to the true coordinates.
Nevertheless, this imputation step will lead to more error for urban addresses than rural addresses.

The INEP data is a catalog of private and public schools with addresses and longitude and latitude.[^2]

[^2]: The data can be found at this [link](https://inepdata.inep.gov.br/analytics/saw.dll?dashboard)

## String Matching

To geocode polling stations, we use fuzzy string matching to match polling stations to coordinates in the administrative datasets by name, address, street, or neighborhood.
This string matching procedure generates several candidate coordinates.
To choose among these possible coordinates, we use a Random Forest model trained on a sample of polling stations with coordinates provided by the election authorities.

The general approach is a follows:

1.  Normalize[^3] name and address of polling station.

2.  Normalize addresses and school names in administrative datasets.

3.  Find the "medioid" (i.e. the median point) for all unique streets and neighborhoods in the CNEFE datasets.

4.  Compute the normalized Levenshtein string distance between polling station name and the names of schools in the INEP and 2010 CNEFE data in the same municipality as the polling station.

5.  Compute the string distance between the address of polling stations and address of schools in INPE and 2010 CNEFE data.

6.  Compute the string distance between the street name and neighborhood name of the polling station and street and neighborhood names from the CNEFE datasets.

[^3]: The normalization function converts all strings to ASCII characters, transforms to lower case, and removes extraneous white space.
    We remove common, but uninformative words, such as "povado" and "localidade".
    We standardize common street abbreviations such as replacing "Av" with "Avenida".
    Finally, for polling station names, we remove words most common in school names, such as "unidade escolar" and "colegio estadual".
    These are very common, yet not used consistently and as a result, are relatively uninformative.
    We found that removing them improves matching performance.

The string matching procedure above generates 8 different potential matches.

### Choosing Among Potential Matches

After string matching, we use a Random Forest model to predict the distance between the possible coordinates and the true coordinates.
We treat the coordinates provided by the election authorities as the "ground truth".
This distance is modeled as a function of the following set of covariates:

-   Normalized Levenshtein string distance.
-   Coordinate data source
-   Indicator for whether the address mentions the city center ("centro")
-   Indicator for whether the address mentions being in the countryside (includes the word "rural")
-   Indicator for whether the address mentions a school
-   Log of municipal population
-   Proportion of the population classified as rural
-   Area of the municipality

We use the implementation of the Random Forest model provided in the `ranger` package.
We set the number of trees to 1000 and use five-fold cross-validation to select the number of variables to use in each tree and the minimum number of units in each leaf node.
After tuning, we train the model on all polling stations with ground truth coordinates.
We then use this model to predict the distance between the true coordinates and the candidate coordinates.
For each polling station, we choose the candidate coordinate with the smallest predicted distance.

### Example of String Matching

```{r load_data}
loadd(inep_string_match, cnefe_stbairro_match, schools_cnefe_match,
      agrocnefe_stbairro_match, locais, geocoded_locais)
```

To illustrate the string matching procedure, the table below shows shows the string matching procedure for one polling station where the coordinates are known.
The blue row shows the selected match.
The last column labeled "Error (km)" is the difference between the known geocoded coordinates and the coordinates from the selected match.

```{r string_match_example}
example_id <- sample(geocoded_locais$local_id[is.na(geocoded_locais$tse_lat) == FALSE], 1)
example_id <- 200351
example_polling_station <- filter(geocoded_locais, local_id == example_id)
example_inep <- filter(inep_string_match, local_id == example_id)
example_cnfe_schools <- filter(schools_cnefe_match, local_id == example_id)
example_agrocnefe <- filter(agrocnefe_stbairro_match, local_id == example_id)
example_cnefe <- filter(cnefe_stbairro_match, local_id == example_id)

table_data <- tibble(Data = c("INEP School Name", "INEP School Address",
                "2010 CNEFE School Name", "2010 CNEFE School Address",
                "2017 CNEFE Street", "2010 CNEFE Street",
                "2017 CNEFE Neighborhood", "2010 CNEFE Neighborhood"),
  `Polling Station String` = c(example_polling_station$normalized_name, 
                               example_polling_station$normalized_addr, 
                               example_polling_station$normalized_name,
                               example_polling_station$normalized_addr,
                               example_polling_station$normalized_st,
                               example_polling_station$normalized_st,
                               example_polling_station$normalized_bairro,
                               example_polling_station$normalized_bairro), 
  Match = c(example_inep$match_inep_name, 
            example_inep$match_inep_addr,
            example_cnfe_schools$match_schools_cnefe_name,
            example_cnfe_schools$match_schools_cnefe_addr,
            example_agrocnefe$match_st_agrocnefe,
            example_cnefe$match_st_cnefe,
            example_agrocnefe$match_bairro_agrocnefe,
            example_cnefe$match_bairro_cnefe), 
  `String Distance` =  c(example_inep$mindist_name_inep, 
                         example_inep$mindist_addr_inep, 
                         example_cnfe_schools$mindist_name_schools_cnefe,
                         example_cnfe_schools$mindist_addr_schools_cnefe,
                         example_agrocnefe$mindist_st_agrocnefe,
                         example_cnefe$mindist_st_cnefe,
                         example_agrocnefe$mindist_bairro_agrocnefe,
                         example_cnefe$mindist_bairro_cnefe),
  long = c(example_inep$match_long_inep_name, 
                         example_inep$match_long_inep_addr, 
                         example_cnfe_schools$match_long_schools_cnefe_name,
                         example_cnfe_schools$match_long_schools_cnefe_addr,
                         example_agrocnefe$match_long_st_agrocnefe,
                         example_cnefe$match_long_st_cnefe,
                         example_agrocnefe$match_long_bairro_agrocnefe,
                         example_cnefe$match_long_bairro_cnefe),
  lat = c(example_inep$match_lat_inep_name, 
                         example_inep$match_lat_inep_addr, 
                         example_cnfe_schools$match_lat_schools_cnefe_name,
                         example_cnfe_schools$match_lat_schools_cnefe_addr,
                         example_agrocnefe$match_lat_st_agrocnefe,
                         example_cnefe$match_lat_st_cnefe,
                         example_agrocnefe$match_lat_bairro_agrocnefe,
                         example_cnefe$match_lat_bairro_cnefe)) %>%
  mutate(rank = rank(`String Distance`, ties.method = "first")) %>%
  rowwise() %>%
  mutate(
    `Error (km)` = geosphere::distHaversine(p1 = c(example_polling_station$long,
                                                   example_polling_station$lat),
                                    p2 = c(long, lat))/1000 
  ) %>%
  select(!long & !lat)


table_data %>%
  gt() %>% 
  cols_hide(vars(rank)) %>%
  fmt_number(matches("String Distance|Error"), 
             decimals = 2) %>%
   tab_header(
    title = "Example of String Matching",
    subtitle = paste0("Polling Station Name is ", example_polling_station$nm_locvot, 
                      ". Polling Station Address is ", example_polling_station$ds_endereco)
  ) %>%
  tab_style(
    style = cell_fill(color = "lightcyan"),
    locations = cells_body(rows = (rank == 1))
  ) %>%
  tab_source_note("Highlighted row is selected match.")
```

To illustrate the string matching procedure, the table above shows shows the string matching procedure for one polling station where the coordinates are known.
The blue row shows the selected match.
The last column labeled "Error (km)" is the difference between the known geocoded coordinates and the coordinates from the selected match.

## Estimating Geocoding Error

```{r gen_error_rate_data, warning=FALSE, message=FALSE}
loadd(best_string_match, tract_shp, google_geocoded_df)

##Need to merge in local_ids into google map geocoded ids
google_geocoded_df <- select(google_geocoded_df, cod_localidade_ibge, zona, num_local,
                             lon, lat) %>%
  rename("nr_zona" = "zona", "nr_locvot" = "num_local",
    "google_long" = "lon", "google_lat" = "lat") %>%
  left_join(select(filter(locais, ano == 2018), cod_localidade_ibge, nr_zona, nr_locvot, local_id)) %>%
  filter(!is.na(local_id)) %>%
  select(local_id, google_long, google_lat)


tsegeocoded_locais <-  left_join(geocoded_locais, best_string_match) %>%
  filter(!is.na(tse_lat) & !is.na(lat)) %>%
  left_join(google_geocoded_df)

rural_urban <-  st_as_sf(filter(tsegeocoded_locais, !is.na(long)), coords = c("long", "lat"), crs = 4674)%>%
  st_join(tract_shp, left = TRUE, largest = TRUE) %>%
  st_drop_geometry()  %>%
  as_tibble() %>%
  select(local_id, zone)

tsegeocoded_locais <- left_join(tsegeocoded_locais, rural_urban)

```

To have some sense of the error of our procedure, we use a subset of `r nrow(tsegeocoded_locais)` with coordinates to check the error of the coordinates generated by our procedure.
These "ground truth" coordinates were provided to the *Estado de Sāo Paulo* by the TSE, which used this data for a story entitled "[Como votou sua vizinhança?](https://www.estadao.com.br/infograficos/politica,como-votou-sua-vizinhanca-explore-o-mapa-mais-detalhado-das-eleicoes,935858)".
We report the error rate at 3 quantiles: 25th, 50th (the median), and the 75th percentile.

In addition to reporting the error rate for the full sample, we also split the sample into polling stations located in rural census tracts versus urban census tracts.
Finally, we compare our error rate to coordinates generated using the Google Maps API.

```{r error_table, message=FALSE, warning=FALSE}

error <-  tsegeocoded_locais %>%
  rowwise() %>%
  mutate(dist = geosphere::distHaversine(p1 = c(long, lat),
                                         p2 = c(tse_long, tse_lat))/1000,
         google_dist = geosphere::distHaversine(p1 = c(long, lat),
                                         p2 = c(google_long, google_lat))/1000)
tibble(Quantile = c("25th", "Median", "75th"),
       `Full Sample` = quantile(error$dist, probs = c(.25, .5, .75), na.rm = TRUE),
       `Urban` = quantile(error$dist[error$zone == "URBANO"], probs = c(.25, .5, .75), na.rm = TRUE),
       `Rural` = quantile(error$dist[error$zone == "RURAL"], probs = c(.25, .5, .75), na.rm = TRUE),
       full_samp_gmaps = quantile(error$google_dist, probs = c(.25, .5, .75), na.rm = TRUE),
       urban_gmaps = quantile(error$google_dist[error$zone == "URBANO"], probs = c(.25, .5, .75), na.rm = TRUE),
       rural_gmaps = quantile(error$google_dist[error$zone == "RURAL"], probs = c(.25, .5, .75), na.rm = TRUE),
       )%>%
  gt() %>%
  fmt_number(2:7, 
             decimals = 2) %>%
  tab_spanner(label = "String Matching", 
              columns = 2:4) %>%
  tab_spanner(label = "Google Maps", 
              columns = 5:7) %>%
  cols_label(full_samp_gmaps = "Full Sample",
             urban_gmaps = "Urban", 
             rural_gmaps = "Rural") %>%
  tab_header(title = "Geocoding Error") %>%
  tab_source_note("Error in kilometers.")

```

As can be seen in the above table, the full sample error rate for our method is about .36 km.
This is substantially higher than the Google Maps geocoding method for the full sample.
This difference, however, is driven by better performance of the Google Maps API in urban census tracts.
In rural census tracts, the string matching procedure performs substantially better: a median error of 1.13 km with string matching vs 8.57 km with Google Maps.

```{r, message=FALSE, warning=FALSE}
group_by(error, match_type) %>%
  summarise(error = median(dist, na.rm = TRUE),
             n = n()) %>%
  mutate(`Matching Variable` = fct_reorder(.f = c("INEP School Name", "INEP School Address",
                "2010 CNEFE School Name", "2010 CNEFE School Address",
                "2017 CNEFE Street", "2010 CNEFE Street",
                "2017 CNEFE Neighborhood", "2010 CNEFE Neighborhood"), error)) %>%
  ggplot(aes(x = error, y = `Matching Variable`, size = n)) + 
  geom_point() + 
  hrbrthemes::theme_ipsum_rc() +
  ggtitle("Error by Match Type") +
  xlab("Median Error")
```

The error rate by matching variable is plotted above.
As expected, error rate tends to be better when we are able to match to a specific school or address.

```{r error_string_distance, warning=FALSE, message=FALSE}
ggplot(error[error$dist < 100, ], aes(x = mindist, y = dist)) + 
  geom_point(size = .1) + 
  scale_y_log10(labels = scales::number) + 
  geom_smooth(se = FALSE) +
  hrbrthemes::theme_ipsum_rc() + 
#  cowplot::theme_cowplot() +
  ylab("Error (km)") + 
  xlab("String Distance") + 
  ggtitle("Error as a Function of String Distance")
```

As expected, geocoding error is partly a function of string distance.
When the string distance between the polling station name or address and the school name or address from the administrative data is large, we should expect more geocoding error.
That said, the relationship is noisy and string distance serves only as a rough guide for error.
